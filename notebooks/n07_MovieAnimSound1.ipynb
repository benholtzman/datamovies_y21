{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our modules: \n",
    "import sys\n",
    "sys.path.append('../2_modules/')\n",
    "import notepicker\n",
    "import makeDataChord_v2 as mDc\n",
    "import writeCmixSco_GRAN_v2 as wRT_gran\n",
    "from subprocess import Popen\n",
    "import subprocess as sp\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# ======================================================\n",
    "# autocheck for your RTcmix installation type: \n",
    "cmixStatus, cmixResult = sp.getstatusoutput(\"CMIX\")\n",
    "if cmixStatus == 0:\n",
    "    cmixInstalled = True\n",
    "    print(\"CMIX found.\")\n",
    "else:\n",
    "    cmixInstalled = False\n",
    "    print(\"CMIX not found, using pyGoRTcmix instead.\")\n",
    "# ======================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPERATURE: \n",
    "\n",
    "# put the data into a dictionary: \n",
    "# (very useful, but we will also work with pandas)\n",
    "data_dict = {}\n",
    "data_dict['time_o'] = time  # the _o indicates these are the original values, un-re-sampled\n",
    "data_dict['p1_o'] = p1 = temp_C\n",
    "\n",
    "# the gransynth instrument ! \n",
    "# http://rtcmix.org/reference/instruments/GRANSYNTH.php\n",
    "\n",
    "# FREQUENCIES\n",
    "# in linear octaves\n",
    "root_freq = 7.0 # what is the lowest value it can have?\n",
    "peak_freq = 8.6\n",
    "p1_scl = np.interp(p1,[min(p1),max(p1)],[root_freq,peak_freq])\n",
    "\n",
    "# AMPLITUDE\n",
    "# absolute amplitude (16-bit, 0-32768)\n",
    "amp_range = [2000,15000]\n",
    "amp = np.interp(p1,[min(p1),max(p1)],amp_range)\n",
    "\n",
    "# PITCHJITTER\n",
    "# p13 (\"PITCHJITTER\") sets the maximum randomly determined amount to add or subtract from the current pitch (in linear octaves).\n",
    "pitchjtr_range = [0.01,0.5]\n",
    "pitchjtr = np.interp(p1,[min(p1),max(p1)],pitchjtr_range)\n",
    "\n",
    "#create RTcmix score\n",
    "reload(wRT_gran)\n",
    "\n",
    "tones_dict = {}\n",
    "#cmixInstalled variable can also be passed to the writeCmixSco module directly from the notebook\n",
    "tones_dict['cmixInstalled'] = cmixInstalled\n",
    "tones_dict['base_name'] = 'Temp_gransynth_LeftCh'\n",
    "tones_dict['dur_sound'] = 20.0\n",
    "\n",
    "# time series: \n",
    "tones_dict['p1'] = p1_scl\n",
    "tones_dict['amplitude'] = amp # = np.array([7000])\n",
    "# add pitchjitter\n",
    "tones_dict['pitchjitter'] = pitchjtr # np.array([2.0]) # \n",
    "\n",
    "# single, constant values\n",
    "#tones_dict['pitchjitter'] = 2.0 \n",
    "tones_dict['hopjitter'] = 0.0\n",
    "\n",
    "wRT_gran.writeCmixSco_GRAN(tones_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play RTcmix score and create a wave file\n",
    "#use CMIX if installed; if not, use pyGoRTcmix\n",
    "if cmixInstalled:\n",
    "    cmix_cmd = 'CMIX < ' + tones_dict['base_name'] + '.sco'\n",
    "else:\n",
    "    cmix_duration = str(tones_dict['dur_sound'])\n",
    "    cmix_cmd = '../pyGoRTcmix/pyGoRTcmix -inputscore ' + os.path.abspath(tones_dict['base_name'] + '.sco ') + '-output ' + os.path.abspath(tones_dict['base_name'] + '.wav ') +'-dur ' + cmix_duration\n",
    "print(cmix_cmd)\n",
    "\n",
    "runCMIX = sp.Popen(cmix_cmd, shell=True) # if can only be called from a shell, use shell=True\n",
    "runCMIX.wait()\n",
    "print('\\nhopefully i just wrote your sound file (' + tones_dict['base_name'] + '.wav); is it here?')\n",
    "! ls *.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT THE SPECTROGRAM\n",
    "filename = tones_dict['base_name'] + '.wav'\n",
    "\n",
    "y, sr = librosa.load(filename)\n",
    "y_db = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max) \n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "librosa.display.specshow(y_db, sr=sr, hop_length=128, x_axis='time', y_axis='log') #y_axis='log'\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Log-frequency power spectrogram')\n",
    "plt.ylim([20,2048])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUMIDITY: \n",
    "\n",
    "# put the data into a dictionary: \n",
    "# (very useful, but we will also work with pandas)\n",
    "data_dict = {}\n",
    "data_dict['time_o'] = time  # the _o indicates these are the original values, un-re-sampled\n",
    "data_dict['p1_o'] = p1 = humidity\n",
    "\n",
    "# the gransynth instrument ! \n",
    "# http://rtcmix.org/reference/instruments/GRANSYNTH.php\n",
    "\n",
    "# FREQUENCIES\n",
    "# in linear octaves\n",
    "root_freq = 6.0 # what is the lowest value it can have?\n",
    "peak_freq = 7.5\n",
    "p1_scl = np.interp(p1,[min(p1),max(p1)],[root_freq,peak_freq])\n",
    "\n",
    "# AMPLITUDE\n",
    "# absolute amplitude (16-bit, 0-32768)\n",
    "amp_range = [7000,18000]\n",
    "amp = np.interp(p1,[min(p1),max(p1)],amp_range)\n",
    "\n",
    "# PITCHJITTER\n",
    "# p13 (\"PITCHJITTER\") sets the maximum randomly determined amount to add or subtract from the current pitch (in linear octaves).\n",
    "pitchjtr_range = [0.01,0.5]\n",
    "pitchjtr = np.interp(p1,[min(p1),max(p1)],pitchjtr_range)\n",
    "\n",
    "#create RTcmix score\n",
    "reload(wRT_gran)\n",
    "\n",
    "tones_dict = {}\n",
    "#cmixInstalled variable can also be passed to the writeCmixSco module directly from the notebook\n",
    "tones_dict['cmixInstalled'] = cmixInstalled\n",
    "tones_dict['base_name'] = 'Humidity_gransynth_RightCh'\n",
    "tones_dict['dur_sound'] = 20.0\n",
    "\n",
    "# time series: \n",
    "tones_dict['p1'] = p1_scl\n",
    "tones_dict['amplitude'] = amp # = np.array([7000])\n",
    "# add pitchjitter\n",
    "tones_dict['pitchjitter'] = pitchjtr # np.array([2.0]) # \n",
    "\n",
    "# single, constant values\n",
    "#tones_dict['pitchjitter'] = 2.0 \n",
    "tones_dict['hopjitter'] = 0.0\n",
    "\n",
    "wRT_gran.writeCmixSco_GRAN(tones_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play RTcmix score and create a wave file\n",
    "#use CMIX if installed; if not, use pyGoRTcmix\n",
    "if cmixInstalled:\n",
    "    cmix_cmd = 'CMIX < ' + tones_dict['base_name'] + '.sco'\n",
    "else:\n",
    "    cmix_duration = str(tones_dict['dur_sound'])\n",
    "    cmix_cmd = '../pyGoRTcmix/pyGoRTcmix -inputscore ' + os.path.abspath(tones_dict['base_name'] + '.sco ') + '-output ' + os.path.abspath(tones_dict['base_name'] + '.wav ') +'-dur ' + cmix_duration\n",
    "print(cmix_cmd)\n",
    "\n",
    "runCMIX = sp.Popen(cmix_cmd, shell=True) # if can only be called from a shell, use shell=True\n",
    "runCMIX.wait()\n",
    "print('\\nhopefully i just wrote your sound file (' + tones_dict['base_name'] + '.wav); is it here?')\n",
    "! ls *.wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT THE SPECTROGRAM\n",
    "\n",
    "filename = tones_dict['base_name'] + '.wav'\n",
    "\n",
    "y, sr = librosa.load(filename)\n",
    "y_db = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max) \n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "librosa.display.specshow(y_db, sr=sr, hop_length=128, x_axis='time', y_axis='log') #y_axis='log'\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Log-frequency power spectrogram')\n",
    "plt.ylim([20,2048])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "## (6) Make the movie by putting the sound and animation together ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE THE MOVIE ! \n",
    "anim_name_in = 'slidingDotsPhaseSpc.avi'\n",
    "\n",
    "sound_name_left = 'Temp_gransynth_LeftCh.wav'\n",
    "sound_name_right = 'Humidity_gransynth_RightCh.wav'\n",
    "stereo_sound_name = 'stereo.wav'\n",
    "\n",
    "movie_snd_name = 'Breathalyzer_v1.avi'\n",
    "\n",
    "#make single stereo track from two mono tracks -- \n",
    "# but this route is less preferable than generating one stereo track from RTcmix directly ! \n",
    "# https://trac.ffmpeg.org/wiki/AudioChannelManipulation\n",
    "# ffmpeg -i left.mp3 -i right.mp3 -filter_complex \"[0:a][1:a]join=inputs=2:channel_layout=stereo[a]\" -map \"[a]\" output.mp3\n",
    "#ffmpeg -i Temp_gransynth_LeftCh.wav -i Humidity_gransynth_RightCh.wav -filter_complex \"[0:a][1:a]join=inputs=2:channel_layout=stereo[a]\" -map \"[a]\" stereo.mp3\n",
    "#ffmpeg -i INPUT1 -i INPUT2 -filter_complex join=inputs=2 OUTPUT\n",
    "#ffmpeg -i Humidity_gransynth_RightCh.wav -i Temp_gransynth_LeftCh.wav -filter_complex join=inputs=2 stereo.mp3\n",
    "\n",
    "# Make single stereo track from two mono tracks -- \n",
    "run_ffmpeg_stereo_cmd = 'ffmpeg -i ' + sound_name_left + ' -i ' + sound_name_right + ' -filter_complex join=inputs=2 ' + stereo_sound_name\n",
    "make_stereo = sp.Popen(run_ffmpeg_stereo_cmd, shell=True) \n",
    "make_stereo.wait()\n",
    "\n",
    "# add the sound file to the movie file ! \n",
    "run_ffmpeg_movie_cmd = 'ffmpeg -i ' + stereo_sound_name + ' -i ' + anim_name_in + ' ' + movie_snd_name\n",
    "make_movie = sp.Popen(run_ffmpeg_movie_cmd, shell=True) \n",
    "make_movie.wait()\n",
    "\n",
    "print(\"And now did i just write your movie; is it here?\")\n",
    "! ls *.avi\n",
    "print(\"BUT beware ! it might take a while to write ! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY WITH FFMPY ! \n",
    "#https://ffmpy.readthedocs.io/en/latest/\n",
    "#https://ffmpy.readthedocs.io/en/latest/examples.html#transcoding\n",
    "    \n",
    "# >>> ff = FFmpeg(\n",
    "# ...     inputs={'video.mp4': None, 'audio.mp3': None},\n",
    "# ...     outputs={'output.ts': '-c:v h264 -c:a ac3'}\n",
    "# ... )\n",
    "# >>> ff.cmd\n",
    "# 'ffmpeg -i audio.mp4 -i video.mp4 -c:v h264 -c:a ac3 output.ts'\n",
    "# >>> ff.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
